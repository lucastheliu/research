{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316615b9",
   "metadata": {},
   "source": [
    "# MLP Model Training\n",
    "\n",
    "This notebook contains the source code necessary to build an MLP classification model using the MNIST dataset. No other resources are required besides the dependencies in the virtual environment and the codes in the `src/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eeb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "from models import MLP\n",
    "from utils import get_mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_model(model, train_loader, lr=1e-3, epochs=5, device='cpu'):\n",
    "    model = model().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(model.fc3(model.relu2(model.fc2(model.relu1(model.fc1(model.flatten(inputs)))))), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 200 == 199:\n",
    "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100:.4f}, Accuracy: {100*correct/total:.2f}%')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        print(f'Epoch {epoch+1} completed, Accuracy: {100*correct/total:.2f}%\\n')\n",
    "\n",
    "    print('Training completed!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597995c",
   "metadata": {},
   "source": [
    "## Exporting the Model\n",
    "\n",
    "The following code block contains the code used to train and export the model to the `models/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f31608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_mnist_loader()\n",
    "device = ('mps' if torch.mps.is_available() else 'cpu')\n",
    "\n",
    "model = train_mlp_model(MLP, train_loader, lr=1e-3, epochs=5, device=device)\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "torch.save(model.state_dict(), '../models/mlp_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
