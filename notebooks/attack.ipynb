{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4533be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInversionAttack:\n",
    "    def __init__(self, model_params, target_class, device):\n",
    "        self.model_params = model_params\n",
    "        self.target_class = target_class\n",
    "        self.device = device\n",
    "\n",
    "    def perform_multimodel_attack(self, models_list, num_iterations=1000, learning_rate=0.01, reg_param=0.01):\n",
    "        \"\"\"\n",
    "        Perform model inversion attack using multiple models with different parameters.\n",
    "\n",
    "        Args:\n",
    "            models_list: List of model parameters for different models\n",
    "            num_iterations: Number of optimization iterations\n",
    "            learning_rate: Learning rate for optimization\n",
    "            reg_param: Regularization parameter for total variation loss\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (recovered image, loss history)\n",
    "        \"\"\"\n",
    "        loaded_models = []\n",
    "        for model_params in models_list:\n",
    "            model = CNN().to(self.device)\n",
    "            model.load_state_dict({k: v.to(self.device) for k, v in model_params.items()})\n",
    "            model.eval()\n",
    "            loaded_models.append(model)\n",
    "\n",
    "        # Initialize the recovered image\n",
    "        recovered_image = torch.rand(1, 1, 28, 28, requires_grad=True, device=self.device)\n",
    "        optimizer = optim.Adam([recovered_image], lr=learning_rate)\n",
    "\n",
    "        # One-hot encode target class\n",
    "        target = torch.zeros(1, 10, device=self.device)\n",
    "        target[0, self.target_class] = 1\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate classification loss across all models\n",
    "            classification_loss = 0\n",
    "            for model in loaded_models:\n",
    "                pred = model(recovered_image)\n",
    "                classification_loss += -torch.sum(target * torch.log(pred + 1e-10))\n",
    "\n",
    "            # Average the classification loss\n",
    "            classification_loss /= len(loaded_models)\n",
    "\n",
    "            # Total variation regularization\n",
    "            tv_loss = torch.sum(torch.abs(recovered_image[:, :, :, :-1] - recovered_image[:, :, :, 1:])) + \\\n",
    "                      torch.sum(torch.abs(recovered_image[:, :, :-1, :] - recovered_image[:, :, 1:, :]))\n",
    "            tv_loss = tv_loss * reg_param\n",
    "\n",
    "            # L2 regularization\n",
    "            l2_loss = torch.sum(recovered_image ** 2) * 0.001\n",
    "\n",
    "            # Combine all losses\n",
    "            total_loss = classification_loss + tv_loss + l2_loss\n",
    "\n",
    "            # Backpropagate and update\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp values to valid image range\n",
    "            with torch.no_grad():\n",
    "                recovered_image.clamp_(0, 1)\n",
    "\n",
    "            # Log progress\n",
    "            if i % 400 == 0:\n",
    "                losses.append(classification_loss.item())\n",
    "                print(f\"[{i}, {classification_loss.item():.4f}]\")\n",
    "\n",
    "        # Convert final result to numpy array\n",
    "        with torch.no_grad():\n",
    "            recovered_image_np = recovered_image.cpu().numpy()\n",
    "\n",
    "        return recovered_image_np, losses\n",
    "\n",
    "    def perform_attack(self, num_iterations=1000, learning_rate=0.01, reg_param=0.01):\n",
    "        model = CNN().to(self.device)\n",
    "        model.load_state_dict({k: v.to(self.device) for k, v in self.model_params.items()})\n",
    "        model.eval()\n",
    "\n",
    "        recovered_image = torch.rand(1, 1, 28, 28, requires_grad=True, device=self.device)\n",
    "        # recovered_image_2 = torch.rand(1, 1, 28, 28, requires_grad=True, device=self.device)\n",
    "\n",
    "        # optimizer = optim.Adam([recovered_image, recovered_image_2], lr=learning_rate)\n",
    "        optimizer = optim.Adam([recovered_image], lr=learning_rate)\n",
    "\n",
    "        target = torch.zeros(1, 10, device=self.device)\n",
    "        target[0, self.target_class] = 1\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(recovered_image)\n",
    "            # pred_2 = model(recovered_image_2)\n",
    "\n",
    "            classification_loss = -torch.sum(target * torch.log(pred + 1e-10)) #-torch.sum(target * torch.log(pred_2 + 1e-10))\n",
    "\n",
    "            tv_loss = torch.sum(torch.abs(recovered_image[:, :, :, :-1] - recovered_image[:, :, :, 1:])) + \\\n",
    "                    torch.sum(torch.abs(recovered_image[:, :, :-1, :] - recovered_image[:, :, 1:, :]))\n",
    "            tv_loss = tv_loss * reg_param\n",
    "\n",
    "            # tv_loss_2 = torch.sum(torch.abs(recovered_image_2[:, :, :, :-1] - recovered_image_2[:, :, :, 1:])) + \\\n",
    "                    # torch.sum(torch.abs(recovered_image_2[:, :, :-1, :] - recovered_image_2[:, :, 1:, :]))\n",
    "            # tv_loss_2 = tv_loss_2 * reg_param\n",
    "\n",
    "            l2_loss = torch.sum(recovered_image ** 2) * 0.001\n",
    "            # l2_loss_2 = torch.sum(recovered_image_2 ** 2) * 0.001\n",
    "\n",
    "            total_loss = classification_loss + tv_loss + l2_loss #+ tv_loss_2 + l2_loss_2\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                recovered_image.clamp_(0, 1)\n",
    "                # recovered_image_2.clamp_(0, 1)\n",
    "\n",
    "            if i % 800 == 0:\n",
    "                losses.append(classification_loss.item())\n",
    "                print(f\"[{i}, {classification_loss.item():.4f}]\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            recovered_image_np = recovered_image.cpu().numpy()\n",
    "            # recovered_image_np = ((recovered_image + recovered_image_2) / 2).cpu().numpy()\n",
    "\n",
    "        return recovered_image_np, losses"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
