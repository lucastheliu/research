{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1df432",
   "metadata": {},
   "source": [
    "# CNN Federated Training Model\n",
    "\n",
    "This notebook contains the source code necessary to build an CNN classification model with federated training using the MNIST dataset. No other resources are required besides the dependencies in the virtual environment and the codes in the `src/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "from models import CNN\n",
    "from utils import get_mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_client_data(dataset, num_clients, iid=True):\n",
    "    def with_iid():\n",
    "        num_items_per_client = len(dataset) // num_clients\n",
    "        client_datasets = []\n",
    "\n",
    "        indices = torch.randperm(len(dataset))\n",
    "        for i in range(num_clients):\n",
    "            start_idx = i * num_items_per_client\n",
    "            end_idx = (i + 1) * num_items_per_client if i < num_clients - 1 else len(dataset)\n",
    "            client_indices = indices[start_idx:end_idx]\n",
    "            client_datasets.append(Subset(dataset, client_indices))\n",
    "\n",
    "        return client_datasets\n",
    "    \n",
    "    def without_iid():\n",
    "        labels = dataset.targets.numpy()\n",
    "        sorted_indices = np.argsort(labels)\n",
    "        client_datasets = []\n",
    "        shards_per_client = 2\n",
    "\n",
    "        num_shards = num_clients * shards_per_client\n",
    "        items_per_shard = len(dataset) // num_shards\n",
    "        shard_indices = []\n",
    "\n",
    "        for i in range(num_shards):\n",
    "            start_idx = i * items_per_shard\n",
    "            end_idx = (i + 1) * items_per_shard if i < num_shards - 1 else len(sorted_indices)\n",
    "            shard_indices.append(sorted_indices[start_idx:end_idx])\n",
    "\n",
    "        np.random.shuffle(shard_indices)\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            client_idx = []\n",
    "            for j in range(shards_per_client):\n",
    "                client_idx.extend(shard_indices[i * shards_per_client + j])\n",
    "            client_datasets.append(Subset(dataset, client_idx))\n",
    "\n",
    "        return client_datasets\n",
    "    \n",
    "    if iid:\n",
    "        return with_iid()\n",
    "    return without_iid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3945ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, dataset, client_id, device):\n",
    "        self.dataset = dataset\n",
    "        self.client_id = client_id\n",
    "        self.device = device\n",
    "        self.model = CNN().to(device)\n",
    "        self.dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    def train(self, epochs=1):\n",
    "        self.model.train()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(self.dataloader)\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        return test_loss, accuracy\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_on_device = {k: v.to(self.device) for k, v in parameters.items()}\n",
    "        self.model.load_state_dict(params_on_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, test_dataset, device):\n",
    "        self.clients = []\n",
    "        self.device = device\n",
    "        self.global_model = CNN().to(device)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "    def add_client(self, client):\n",
    "        self.clients.append(client)\n",
    "\n",
    "    def aggregate_parameters(self, client_parameters):\n",
    "        global_dict = OrderedDict()\n",
    "\n",
    "        for k in client_parameters[0].keys():\n",
    "            global_dict[k] = torch.stack([client_parameters[i][k] for i in range(len(client_parameters))], 0).mean(0)\n",
    "\n",
    "        return global_dict\n",
    "\n",
    "    def update_global_model(self):\n",
    "        client_parameters = [client.get_parameters() for client in self.clients]\n",
    "        global_parameters = self.aggregate_parameters(client_parameters)\n",
    "\n",
    "        self.global_model.load_state_dict({k: v.to(self.device) for k, v in global_parameters.items()})\n",
    "\n",
    "        for client in self.clients:\n",
    "            client.set_parameters(global_parameters)\n",
    "\n",
    "        return client_parameters[0]  # Return client 1's parameters for potential attack\n",
    "\n",
    "    def evaluate_global_model(self):\n",
    "        self.global_model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.global_model(data)\n",
    "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(self.test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(self.test_loader.dataset)\n",
    "\n",
    "        return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_federated_learning(num_clients=3, num_rounds=3, local_epochs=1, iid=False, device='cpu'):\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_dataset, test_dataset = get_mnist_dataset()\n",
    "    client_datasets = distribute_client_data(train_dataset, num_clients, iid=iid)\n",
    "\n",
    "    server = Server(test_dataset, device)\n",
    "    clients = []\n",
    "    client_params_list = []\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        client = Client(client_datasets[i], i, device)\n",
    "        clients.append(client)\n",
    "        server.add_client(client)\n",
    "\n",
    "    global_accuracies = []\n",
    "    client_losses = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        client_params_list.append([])\n",
    "\n",
    "        print(f\"\\nRound {round_num+1}/{num_rounds}\")\n",
    "\n",
    "        for i, client in enumerate(clients):\n",
    "            loss = client.train(epochs=local_epochs)\n",
    "            client_losses[i].append(loss)\n",
    "            print(f\"Client {i+1} loss: {loss:.4f}\")\n",
    "\n",
    "            client_params_list[round_num].append(client.get_parameters())\n",
    "\n",
    "        server.update_global_model()\n",
    "        test_loss, accuracy = server.evaluate_global_model()\n",
    "        global_accuracies.append(accuracy)\n",
    "        print(f\"Global model - Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    options = {\n",
    "        'num_clients': num_clients,\n",
    "        'num_rounds': num_rounds,\n",
    "        'local_epochs': local_epochs,\n",
    "        'iid': iid,\n",
    "        'device': device\n",
    "    }\n",
    "\n",
    "    return clients, options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4fc0f",
   "metadata": {},
   "source": [
    "## Exporting the Model\n",
    "\n",
    "The following code blocks contain the code used to train the client models, perform federated averaging, and export all of the models to the `models/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('mps' if torch.mps.is_available() else 'cpu')\n",
    "\n",
    "clients, options = run_federated_learning(\n",
    "    num_clients=5,\n",
    "    num_rounds=3,\n",
    "    local_epochs=1,\n",
    "    iid=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "os.makedirs('../models/clients', exist_ok=True)\n",
    "model_params = [clients[i].get_parameters() for i in range(options['num_clients'])]\n",
    "\n",
    "for index, model_param in enumerate(model_params):\n",
    "    model = CNN()\n",
    "    model.load_state_dict(model_param)\n",
    "    torch.save(model.state_dict(), f'../models/clients/model-{index}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_models(param_list):\n",
    "    avg_params = OrderedDict()\n",
    "    \n",
    "    for key in param_list[0].keys():\n",
    "        avg_params[key] = torch.stack([params[key].float() for params in param_list], dim=0).mean(dim=0)\n",
    "\n",
    "    return avg_params\n",
    "\n",
    "global_params = average_models(model_params)\n",
    "global_model = CNN()\n",
    "global_model.load_state_dict(global_params)\n",
    "torch.save(global_model.state_dict(), '../models/federated_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
