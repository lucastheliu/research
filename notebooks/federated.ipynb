{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967555f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout1(F.max_pool2d(x, 2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(self.dropout2(x))\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataset():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_client_data(dataset, num_clients, iid=True):\n",
    "    if iid:\n",
    "        num_items_per_client = len(dataset) // num_clients\n",
    "        client_datasets = []\n",
    "\n",
    "        indices = torch.randperm(len(dataset))\n",
    "        for i in range(num_clients):\n",
    "            start_idx = i * num_items_per_client\n",
    "            end_idx = (i + 1) * num_items_per_client if i < num_clients - 1 else len(dataset)\n",
    "            client_indices = indices[start_idx:end_idx]\n",
    "            client_datasets.append(Subset(dataset, client_indices))\n",
    "    else:\n",
    "        labels = dataset.targets.numpy()\n",
    "        sorted_indices = np.argsort(labels)\n",
    "        client_datasets = []\n",
    "        shards_per_client = 2\n",
    "\n",
    "        num_shards = num_clients * shards_per_client\n",
    "        items_per_shard = len(dataset) // num_shards\n",
    "        shard_indices = []\n",
    "\n",
    "        for i in range(num_shards):\n",
    "            start_idx = i * items_per_shard\n",
    "            end_idx = (i + 1) * items_per_shard if i < num_shards - 1 else len(sorted_indices)\n",
    "            shard_indices.append(sorted_indices[start_idx:end_idx])\n",
    "\n",
    "        np.random.shuffle(shard_indices)\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            client_idx = []\n",
    "            for j in range(shards_per_client):\n",
    "                client_idx.extend(shard_indices[i * shards_per_client + j])\n",
    "            client_datasets.append(Subset(dataset, client_idx))\n",
    "\n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb3945ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, dataset, client_id, device):\n",
    "        self.dataset = dataset\n",
    "        self.client_id = client_id\n",
    "        self.device = device\n",
    "        self.model = CNN().to(device)\n",
    "        self.dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    def train(self, epochs=1):\n",
    "        self.model.train()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for batch_idx, (data, target) in enumerate(self.dataloader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(self.dataloader)\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        return test_loss, accuracy\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_on_device = {k: v.to(self.device) for k, v in parameters.items()}\n",
    "        self.model.load_state_dict(params_on_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b80e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, test_dataset, device):\n",
    "        self.clients = []\n",
    "        self.device = device\n",
    "        self.global_model = CNN().to(device)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "    def add_client(self, client):\n",
    "        self.clients.append(client)\n",
    "\n",
    "    def aggregate_parameters(self, client_parameters):\n",
    "        global_dict = OrderedDict()\n",
    "\n",
    "        for k in client_parameters[0].keys():\n",
    "            global_dict[k] = torch.stack([client_parameters[i][k] for i in range(len(client_parameters))], 0).mean(0)\n",
    "\n",
    "        return global_dict\n",
    "\n",
    "    def update_global_model(self):\n",
    "        client_parameters = [client.get_parameters() for client in self.clients]\n",
    "        global_parameters = self.aggregate_parameters(client_parameters)\n",
    "\n",
    "        self.global_model.load_state_dict({k: v.to(self.device) for k, v in global_parameters.items()})\n",
    "\n",
    "        for client in self.clients:\n",
    "            client.set_parameters(global_parameters)\n",
    "\n",
    "        return client_parameters[0]  # Return client 1's parameters for potential attack\n",
    "\n",
    "    def evaluate_global_model(self):\n",
    "        self.global_model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.global_model(data)\n",
    "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(self.test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(self.test_loader.dataset)\n",
    "\n",
    "        return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_federated_learning(num_clients=3, num_rounds=3, local_epochs=1, iid=False, device='cpu'):\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_dataset, test_dataset = get_mnist_dataset()\n",
    "    client_datasets = distribute_client_data(train_dataset, num_clients, iid=iid)\n",
    "\n",
    "    server = Server(test_dataset, device)\n",
    "    clients = []\n",
    "    client_params_list = []\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        client = Client(client_datasets[i], i, device)\n",
    "        clients.append(client)\n",
    "        server.add_client(client)\n",
    "\n",
    "    global_accuracies = []\n",
    "    client_losses = [[] for _ in range(num_clients)]\n",
    "\n",
    "    # Federated learning loop\n",
    "    for round_num in range(num_rounds):\n",
    "        client_params_list.append([])\n",
    "\n",
    "        print(f\"\\nRound {round_num+1}/{num_rounds}\")\n",
    "\n",
    "        for i, client in enumerate(clients):\n",
    "            loss = client.train(epochs=local_epochs)\n",
    "            client_losses[i].append(loss)\n",
    "            print(f\"Client {i+1} loss: {loss:.4f}\")\n",
    "\n",
    "            client_params_list[round_num].append(client.get_parameters())\n",
    "\n",
    "        server.update_global_model()\n",
    "        test_loss, accuracy = server.evaluate_global_model()\n",
    "        global_accuracies.append(accuracy)\n",
    "        print(f\"Global model - Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return (global_accuracies, client_losses), (server, clients, client_params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0df4ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Round 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucastheliu/Projects/research/.venv/lib/python3.13/site-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 loss: 1.8023\n",
      "Client 2 loss: 1.7548\n",
      "Client 3 loss: 1.7869\n",
      "Client 4 loss: 1.8559\n",
      "Client 5 loss: 1.7742\n",
      "Client 6 loss: 1.7964\n",
      "Client 7 loss: 1.8075\n",
      "Client 8 loss: 1.7904\n",
      "Client 9 loss: 1.7917\n",
      "Client 10 loss: 1.7837\n",
      "Global model - Test loss: 2.3022, Accuracy: 16.31%\n",
      "\n",
      "Round 2/10\n",
      "Client 1 loss: 1.8384\n",
      "Client 2 loss: 1.8285\n",
      "Client 3 loss: 1.8238\n",
      "Client 4 loss: 1.8366\n",
      "Client 5 loss: 1.8291\n",
      "Client 6 loss: 1.8364\n",
      "Client 7 loss: 1.8331\n",
      "Client 8 loss: 1.8176\n",
      "Client 9 loss: 1.8366\n",
      "Client 10 loss: 1.8377\n",
      "Global model - Test loss: 1.6013, Accuracy: 86.92%\n",
      "\n",
      "Round 3/10\n",
      "Client 1 loss: 1.6747\n",
      "Client 2 loss: 1.6663\n",
      "Client 3 loss: 1.6617\n",
      "Client 4 loss: 1.6657\n",
      "Client 5 loss: 1.6690\n",
      "Client 6 loss: 1.6701\n",
      "Client 7 loss: 1.6639\n",
      "Client 8 loss: 1.6649\n",
      "Client 9 loss: 1.6713\n",
      "Client 10 loss: 1.6879\n",
      "Global model - Test loss: 1.5606, Accuracy: 90.20%\n",
      "\n",
      "Round 4/10\n",
      "Client 1 loss: 1.6394\n",
      "Client 2 loss: 1.6333\n",
      "Client 3 loss: 1.6396\n",
      "Client 4 loss: 1.6375\n",
      "Client 5 loss: 1.6348\n",
      "Client 6 loss: 1.6276\n",
      "Client 7 loss: 1.6388\n",
      "Client 8 loss: 1.6400\n",
      "Client 9 loss: 1.6362\n",
      "Client 10 loss: 1.6484\n",
      "Global model - Test loss: 1.5459, Accuracy: 91.74%\n",
      "\n",
      "Round 5/10\n",
      "Client 1 loss: 1.6012\n",
      "Client 2 loss: 1.6036\n",
      "Client 3 loss: 1.6059\n",
      "Client 4 loss: 1.6067\n",
      "Client 5 loss: 1.6104\n",
      "Client 6 loss: 1.6137\n",
      "Client 7 loss: 1.6029\n",
      "Client 8 loss: 1.6089\n",
      "Client 9 loss: 1.6117\n",
      "Client 10 loss: 1.6118\n",
      "Global model - Test loss: 1.5333, Accuracy: 92.88%\n",
      "\n",
      "Round 6/10\n",
      "Client 1 loss: 1.5852\n",
      "Client 2 loss: 1.5788\n",
      "Client 3 loss: 1.5837\n",
      "Client 4 loss: 1.5894\n",
      "Client 5 loss: 1.5902\n",
      "Client 6 loss: 1.5873\n",
      "Client 7 loss: 1.5855\n",
      "Client 8 loss: 1.5863\n",
      "Client 9 loss: 1.5792\n",
      "Client 10 loss: 1.5826\n",
      "Global model - Test loss: 1.5212, Accuracy: 94.04%\n",
      "\n",
      "Round 7/10\n",
      "Client 1 loss: 1.5664\n",
      "Client 2 loss: 1.5636\n",
      "Client 3 loss: 1.5695\n",
      "Client 4 loss: 1.5658\n",
      "Client 5 loss: 1.5772\n",
      "Client 6 loss: 1.5684\n",
      "Client 7 loss: 1.5678\n",
      "Client 8 loss: 1.5655\n",
      "Client 9 loss: 1.5703\n",
      "Client 10 loss: 1.5627\n",
      "Global model - Test loss: 1.5123, Accuracy: 94.89%\n",
      "\n",
      "Round 8/10\n",
      "Client 1 loss: 1.5513\n",
      "Client 2 loss: 1.5528\n",
      "Client 3 loss: 1.5526\n",
      "Client 4 loss: 1.5558\n",
      "Client 5 loss: 1.5571\n",
      "Client 6 loss: 1.5544\n",
      "Client 7 loss: 1.5585\n",
      "Client 8 loss: 1.5496\n",
      "Client 9 loss: 1.5507\n",
      "Client 10 loss: 1.5552\n",
      "Global model - Test loss: 1.5053, Accuracy: 95.69%\n",
      "\n",
      "Round 9/10\n",
      "Client 1 loss: 1.5433\n",
      "Client 2 loss: 1.5366\n",
      "Client 3 loss: 1.5418\n",
      "Client 4 loss: 1.5432\n",
      "Client 5 loss: 1.5418\n",
      "Client 6 loss: 1.5463\n",
      "Client 7 loss: 1.5346\n",
      "Client 8 loss: 1.5422\n",
      "Client 9 loss: 1.5469\n",
      "Client 10 loss: 1.5445\n",
      "Global model - Test loss: 1.5015, Accuracy: 95.94%\n",
      "\n",
      "Round 10/10\n",
      "Client 1 loss: 1.5388\n",
      "Client 2 loss: 1.5324\n",
      "Client 3 loss: 1.5398\n",
      "Client 4 loss: 1.5367\n",
      "Client 5 loss: 1.5341\n",
      "Client 6 loss: 1.5422\n",
      "Client 7 loss: 1.5365\n",
      "Client 8 loss: 1.5380\n",
      "Client 9 loss: 1.5445\n",
      "Client 10 loss: 1.5350\n",
      "Global model - Test loss: 1.4973, Accuracy: 96.40%\n"
     ]
    }
   ],
   "source": [
    "num_clients = 10\n",
    "device = (\n",
    "    'mps' if torch.mps.is_available()\n",
    "    else 'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "\n",
    "(global_accuracies, client_losses), (server, clients, client_params_list) = run_federated_learning(\n",
    "    num_clients=10,\n",
    "    num_rounds=10,\n",
    "    local_epochs=1,\n",
    "    iid=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model_params = [clients[i].get_parameters() for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "613bb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_models(param_list):\n",
    "    avg_params = OrderedDict()\n",
    "    \n",
    "    for key in param_list[0].keys():\n",
    "        avg_params[key] = torch.stack([params[key].float() for params in param_list], dim=0).mean(dim=0)\n",
    "\n",
    "    return avg_params\n",
    "\n",
    "global_params = average_models(model_params)\n",
    "\n",
    "global_model = CNN()\n",
    "global_model.load_state_dict(global_params)\n",
    "torch.save(global_model.state_dict(), '../models/federated_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
