{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Differential Privacy\n",
        "\n",
        "Differential privacy is a method used to ensure individuals' privacy when sharing or analyzing data. The core idea is to add controlled random noise to the data or analysis results so that it becomes difficult to identify specific individuals, even if someone has access to the output of a data analysis. The amount of noise added is carefully controlled to balance privacy and accuracy, with a parameter called epsilon (ε) determining the level of privacy protection—smaller values of ε lead to stronger privacy but less accuracy.\n",
        "\n",
        "This approach is used in various sectors like government surveys, tech companies, and medical research to protect sensitive information while still allowing valuable insights to be derived. By ensuring that the inclusion of any individual’s data doesn’t significantly impact the results, differential privacy helps organizations conduct data analysis without compromising personal privacy."
      ],
      "metadata": {
        "id": "rv-c7o5npxeZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umlrwgMOSjTl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(64 * 5 * 5, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mJynJTkySnJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"\\nusing device: {device}\")"
      ],
      "metadata": {
        "id": "Y8n8PsFeTFMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for images, labels in tqdm(\n",
        "\t\titerable=train_loader,\n",
        "\t\tdesc=f\"[{epoch:{len(str(num_epochs))}d}/{num_epochs:{len(str(num_epochs))}d}]\"\n",
        "\t):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    print(f\"--> loss={epoch_loss:.4f}, accuracy={accuracy:.2f}%\\n\")\n",
        "\n",
        "print(\"Training complete!\\n\")"
      ],
      "metadata": {
        "id": "0b_01neDS3CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(\n",
        "        iterable=test_loader,\n",
        "        desc=\"evaluate\"\n",
        "    ):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "YMCt0qPhZIJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inversion Attack"
      ],
      "metadata": {
        "id": "5J-PfiV-qZBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inversion_attack(model, target_class, learning_rate, iterations, reg_param, l2_param):\n",
        "    model.eval()\n",
        "\n",
        "    recovered_image = torch.rand(1, 1, 28, 28, requires_grad=True, device=device)\n",
        "    optimizer = optim.Adam([recovered_image], lr=learning_rate)\n",
        "\n",
        "    target = torch.zeros(1, 10, device=device)\n",
        "    target[0, target_class] = 1\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for i in tqdm(range(iterations), desc=\"inversion_attack\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(recovered_image)\n",
        "        classification_loss = F.cross_entropy(pred, target.argmax(dim=1))\n",
        "\n",
        "        tv_loss = torch.sum(torch.abs(recovered_image[:, :, :, :-1] - recovered_image[:, :, :, 1:])) + \\\n",
        "                  torch.sum(torch.abs(recovered_image[:, :, :-1, :] - recovered_image[:, :, 1:, :]))\n",
        "\n",
        "        tv_loss *= reg_param\n",
        "        l2_loss = torch.sum(recovered_image ** 2) * l2_param\n",
        "        total_loss = classification_loss + tv_loss + l2_loss\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            recovered_image.clamp_(0, 1)\n",
        "\n",
        "        if i % 500 == 499:\n",
        "            losses.append(classification_loss.item())\n",
        "            print(f'[{i + 1:4d}] loss: {classification_loss.item():.6f}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image = recovered_image.cpu().squeeze().numpy()\n",
        "\n",
        "    return (image, losses)"
      ],
      "metadata": {
        "id": "zLrUJ-WAT3Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Noise Layer to Model"
      ],
      "metadata": {
        "id": "6BB7VeFoqbeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_level = 0.13\n",
        "\n",
        "noised_model = CNN().to(device)\n",
        "noised_model.load_state_dict(model.state_dict())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for param in noised_model.parameters():\n",
        "        param.add_(torch.randn_like(param) * noise_level)"
      ],
      "metadata": {
        "id": "iykOuOqgUI1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noised_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(\n",
        "        iterable=test_loader,\n",
        "        desc=\"evaluate\"\n",
        "    ):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = noised_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "w3j1z2T5U1nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack Model and Noised Model"
      ],
      "metadata": {
        "id": "_2y5equ0qgWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_class = 8\n",
        "\n",
        "(image, losses) = inversion_attack(\n",
        "\tmodel=model,\n",
        "\ttarget_class=target_class,\n",
        "\tlearning_rate=0.01,\n",
        "\titerations=2000,\n",
        "\treg_param=1e-5,\n",
        "\tl2_param=1e-3\n",
        ")\n",
        "\n",
        "(noised_image, noised_losses) = inversion_attack(\n",
        "\tmodel=noised_model,\n",
        "\ttarget_class=target_class,\n",
        "\tlearning_rate=0.01,\n",
        "\titerations=2000,\n",
        "\treg_param=1e-5,\n",
        "\tl2_param=1e-3\n",
        ")"
      ],
      "metadata": {
        "id": "aeAE-EzGoUKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Images"
      ],
      "metadata": {
        "id": "zcPwfglAqkPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "fig, axis = plt.subplots(1, 2)\n",
        "\n",
        "axis[0].imshow(image, cmap='gray')\n",
        "axis[0].axis('off')\n",
        "\n",
        "axis[1].imshow(noised_image, cmap='gray')\n",
        "axis[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JNMGWr8poVdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axis = plt.subplots(2, 10, figsize=(13, 4))\n",
        "\n",
        "for i in range(10):\n",
        "    (image, losses) = inversion_attack(\n",
        "        model=model,\n",
        "        target_class=i,\n",
        "        learning_rate=0.01,\n",
        "        iterations=2000,\n",
        "        reg_param=1e-5,\n",
        "        l2_param=1e-3\n",
        "    )\n",
        "\n",
        "    (noised_image, noised_losses) = inversion_attack(\n",
        "        model=noised_model,\n",
        "        target_class=i,\n",
        "        learning_rate=0.01,\n",
        "        iterations=2000,\n",
        "        reg_param=1e-5,\n",
        "        l2_param=1e-3\n",
        "    )\n",
        "\n",
        "    axis[0, i].imshow(image, cmap='gray')\n",
        "    axis[0, i].axis('off')\n",
        "\n",
        "    axis[1, i].imshow(noised_image, cmap='gray')\n",
        "    axis[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wfwJ49lFoWtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Federated Learning"
      ],
      "metadata": {
        "id": "Mcqz_UXmloAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, dataset, client_id, device):\n",
        "        self.dataset = dataset\n",
        "        self.client_id = client_id\n",
        "        self.device = device\n",
        "        self.model = CNN().to(device)\n",
        "        self.dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    def train(self, epochs=1, noise_level=0.0):\n",
        "        self.model.train()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        total_loss = 0\n",
        "\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "\n",
        "            for data, target in tqdm(\n",
        "                iterable=self.dataloader,\n",
        "                desc=f\"[{epoch:{len(str(epochs))}d}/{epochs:{len(str(epochs))}d}]\"\n",
        "            ):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output = self.model(data)\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for param in self.model.parameters():\n",
        "                param.add_(torch.randn_like(param) * noise_level)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        return total_loss / len(self.dataloader), accuracy\n",
        "\n",
        "    def evaluate(self, test_loader):\n",
        "        self.model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "        return test_loss, accuracy\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_on_device = {k: v.to(self.device) for k, v in parameters.items()}\n",
        "        self.model.load_state_dict(params_on_device)"
      ],
      "metadata": {
        "id": "UvnK8oqilnm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, test_dataset, device):\n",
        "        self.clients = []\n",
        "        self.device = device\n",
        "        self.global_model = CNN().to(device)\n",
        "        self.test_loader = DataLoader(test_dataset, batch_size=128)\n",
        "\n",
        "    def add_client(self, client):\n",
        "        self.clients.append(client)\n",
        "\n",
        "    def aggregate_parameters(self, client_parameters):\n",
        "        global_dict = OrderedDict()\n",
        "\n",
        "        for k in client_parameters[0].keys():\n",
        "            global_dict[k] = torch.stack([client_parameters[i][k] for i in range(len(client_parameters))], 0).mean(0)\n",
        "\n",
        "        return global_dict\n",
        "\n",
        "    def update_global_model(self):\n",
        "        client_parameters = [client.get_parameters() for client in self.clients]\n",
        "        global_parameters = self.aggregate_parameters(client_parameters)\n",
        "\n",
        "        self.global_model.load_state_dict({k: v.to(self.device) for k, v in global_parameters.items()})\n",
        "\n",
        "        for client in self.clients:\n",
        "            client.set_parameters(global_parameters)\n",
        "\n",
        "        return client_parameters[0]  # Return client 1's parameters for potential attack\n",
        "\n",
        "    def evaluate_global_model(self):\n",
        "        self.global_model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in self.test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.global_model(data)\n",
        "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(self.test_loader.dataset)\n",
        "        accuracy = 100. * correct / len(self.test_loader.dataset)\n",
        "\n",
        "        return test_loss, accuracy"
      ],
      "metadata": {
        "id": "463kCySSmHjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "    return train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "rzwyoJ_WmnS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "def distribute_data(dataset, num_clients, iid=True):\n",
        "    if iid:\n",
        "        num_items_per_client = len(dataset) // num_clients\n",
        "        client_datasets = []\n",
        "\n",
        "        indices = torch.randperm(len(dataset))\n",
        "        for i in range(num_clients):\n",
        "            start_idx = i * num_items_per_client\n",
        "            end_idx = (i + 1) * num_items_per_client if i < num_clients - 1 else len(dataset)\n",
        "            client_indices = indices[start_idx:end_idx]\n",
        "            client_datasets.append(Subset(dataset, client_indices))\n",
        "    else:\n",
        "        labels = dataset.targets.numpy()\n",
        "        sorted_indices = np.argsort(labels)\n",
        "        client_datasets = []\n",
        "        shards_per_client = 2\n",
        "\n",
        "        num_shards = num_clients * shards_per_client\n",
        "        items_per_shard = len(dataset) // num_shards\n",
        "        shard_indices = []\n",
        "\n",
        "        for i in range(num_shards):\n",
        "            start_idx = i * items_per_shard\n",
        "            end_idx = (i + 1) * items_per_shard if i < num_shards - 1 else len(sorted_indices)\n",
        "            shard_indices.append(sorted_indices[start_idx:end_idx])\n",
        "\n",
        "        np.random.shuffle(shard_indices)\n",
        "\n",
        "        for i in range(num_clients):\n",
        "            client_idx = []\n",
        "            for j in range(shards_per_client):\n",
        "                client_idx.extend(shard_indices[i * shards_per_client + j])\n",
        "            client_datasets.append(Subset(dataset, client_idx))\n",
        "\n",
        "    return client_datasets"
      ],
      "metadata": {
        "id": "hP_JdOsamlG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_federated_learning(num_clients=3, num_rounds=3, local_epochs=1, noise_level=0.0, iid=False):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_dataset, test_dataset = load_mnist()\n",
        "    client_datasets = distribute_data(train_dataset, num_clients, iid=iid)\n",
        "\n",
        "    server = Server(test_dataset, device)\n",
        "    clients = []\n",
        "    client_params_list = []\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client = Client(client_datasets[i], i, device)\n",
        "        clients.append(client)\n",
        "        server.add_client(client)\n",
        "\n",
        "    global_accuracies = []\n",
        "    client_losses = [[] for _ in range(num_clients)]\n",
        "\n",
        "    # Federated learning loop\n",
        "    for round_num in range(num_rounds):\n",
        "        client_params_list.append([])\n",
        "\n",
        "        print(f\"\\nRound {round_num+1}/{num_rounds}\")\n",
        "\n",
        "        for i, client in enumerate(clients):\n",
        "            loss, accuracy = client.train(epochs=local_epochs, noise_level=noise_level)\n",
        "            client_losses[i].append(loss)\n",
        "            print(f\"[Client {i+1}] loss={loss:.4f}, accuracy={accuracy:.2f}%\")\n",
        "\n",
        "            client_params_list[round_num].append(client.get_parameters())\n",
        "\n",
        "        server.update_global_model()\n",
        "        test_loss, accuracy = server.evaluate_global_model()\n",
        "        global_accuracies.append(accuracy)\n",
        "        print(f\"Global model - Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return (global_accuracies, client_losses), (server, clients, client_params_list)"
      ],
      "metadata": {
        "id": "6qTYghSRmU9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_clients = 10\n",
        "num_rounds = 5\n",
        "\n",
        "local_epochs = 1\n",
        "noise_level = 0.0\n",
        "iid = True"
      ],
      "metadata": {
        "id": "KGVki3qM6GqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "4E4W56kv1h78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, (server, clients, _) = run_federated_learning(\n",
        "    num_clients=num_clients,\n",
        "    num_rounds=num_rounds,\n",
        "    local_epochs=local_epochs,\n",
        "    noise_level=noise_level,\n",
        "    iid=iid\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_params = [clients[i].get_parameters() for i in range(num_clients)]"
      ],
      "metadata": {
        "id": "TamKc2immXze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inversion Attack on Federated Learning"
      ],
      "metadata": {
        "id": "c9h-sZVZpywY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelInversionAttack:\n",
        "    def __init__(self, model_params, target_class, device):\n",
        "        self.model_params = model_params\n",
        "        self.target_class = target_class\n",
        "        self.device = device\n",
        "\n",
        "    def inversion(self, target_name, num_iterations=1000, learning_rate=0.01, reg_param=0.01):\n",
        "        model = CNN().to(self.device)\n",
        "        model.load_state_dict({k: v.to(self.device) for k, v in self.model_params.items()})\n",
        "        model.eval()\n",
        "\n",
        "        recovered_image = torch.rand(1, 1, 28, 28, requires_grad=True, device=self.device)\n",
        "        optimizer = optim.Adam([recovered_image], lr=learning_rate)\n",
        "\n",
        "        target = torch.zeros(1, 10, device=self.device)\n",
        "        target[0, self.target_class] = 1\n",
        "\n",
        "        losses = []\n",
        "        classification_loss = 0\n",
        "        correct_predictions = 0\n",
        "\n",
        "        for i in tqdm(range(num_iterations), desc=f\"attack [{target_name}]\"):\n",
        "            optimizer.zero_grad()\n",
        "            classification_loss = 0\n",
        "\n",
        "            pred = model(recovered_image)\n",
        "            pred_prob = F.softmax(pred, dim=1)\n",
        "            classification_loss += -torch.sum(target * torch.log(pred_prob + 1e-10))\n",
        "\n",
        "            predicted_class = torch.argmax(pred_prob, dim=1)\n",
        "            if predicted_class == self.target_class:\n",
        "                correct_predictions += 1\n",
        "\n",
        "            tv_loss = torch.sum(torch.abs(recovered_image[:, :, :, :-1] - recovered_image[:, :, :, 1:])) + \\\n",
        "                      torch.sum(torch.abs(recovered_image[:, :, :-1, :] - recovered_image[:, :, 1:, :]))\n",
        "            tv_loss = tv_loss * reg_param\n",
        "\n",
        "            l2_loss = torch.sum(recovered_image ** 2) * 0.001\n",
        "\n",
        "            total_loss = classification_loss + tv_loss + l2_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                recovered_image.clamp_(0, 1)\n",
        "\n",
        "        accuracy = (correct_predictions / (num_iterations)) * 100\n",
        "\n",
        "        print(f\"--> loss={classification_loss.item():.4f}, accuracy={accuracy:.2f}%\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            recovered_image_np = recovered_image.cpu().numpy()\n",
        "\n",
        "        return recovered_image_np, losses"
      ],
      "metadata": {
        "id": "3wJsokuroaHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "target_class = 5 # Class to attack\n",
        "\n",
        "for model_param in model_params:\n",
        "    images = []\n",
        "\n",
        "    attack = ModelInversionAttack(model_param, target_class, device)\n",
        "    test_loader = torch.utils.data.DataLoader(datasets.MNIST('./data', train=False, transform=transforms.ToTensor()), batch_size=64)\n",
        "\n",
        "    attacked_image, _ = attack.inversion(\n",
        "        target_name=target_class,\n",
        "        num_iterations=400, # 1000\n",
        "        learning_rate=0.1,  # 0.01\n",
        "        reg_param=1e-4      # 1e-5\n",
        "    )\n",
        "    attacked_image = np.squeeze(attacked_image)\n",
        "\n",
        "    images.append(attacked_image)\n",
        "    results.append(images)\n",
        "\n",
        "# Server attack\n",
        "global_params =  {k: v.cpu() for k, v in server.global_model.state_dict().items()}\n",
        "\n",
        "attack = ModelInversionAttack(global_params, target_class, device)\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST('./data', train=False, transform=transforms.ToTensor()), batch_size=64)\n",
        "\n",
        "global_image, _ = attack.inversion(\n",
        "    target_name=target_class,\n",
        "    num_iterations=1000, # 1000\n",
        "    learning_rate=0.01,  # 0.01\n",
        "    reg_param=1e-5      # 1e-5\n",
        ")\n",
        "global_image = np.squeeze(global_image)"
      ],
      "metadata": {
        "id": "g5BD3tL5pKA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(10, 6))\n",
        "round = 0\n",
        "\n",
        "for y in range(3):\n",
        "    for x in range(4):\n",
        "        if round <= 9:\n",
        "            axes[y][x].imshow(results[round][0], cmap='gray')\n",
        "            axes[y][x].set_title(f\"Client {round + 1}\")\n",
        "        axes[y][x].axis(\"off\")\n",
        "        round += 1\n",
        "\n",
        "axes[2][3].imshow(global_image, cmap='gray')\n",
        "axes[2][3].set_title(f\"Server\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AwkUnpYpprke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}